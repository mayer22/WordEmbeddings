# Word Embedding Resources
I have provided several resources for learning about word embeddings, specifically Word2Vec.

* Lecture slides that introduce and explain word embeddings. They also compare Word2Vec to other NLP techniques and demonstrate its importance to NLP through examples and visualizations.
* Python notebook, TrainW2V_KerasRoyal, that demonstrates how word embeddings are created from scratch (using keras) along with a small corresponding input data file, royalData.
* Python notebook, TrainW2V_GenSimText8, that demonstrates training a much larger word embedding model (using gensim) on an API accessible dataset.

Some additional links for exploring word embeddings
* Demo: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/index.html
* Tutorial: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/tutorial.html
* Experiments: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/experiments.html
* Published Paper: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/EAAI-2022-Word-Embedding.pdf
