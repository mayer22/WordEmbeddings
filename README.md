# Word Embedding Resources
I have provided several resources for learning about word embeddings, specifically word2vec.

* Lecture slides, _NLPLecture_, that introduce and explain word embeddings. They also compare word2vec to other NLP techniques and demonstrate its importance to NLP through examples and visualizations.
* Python notebook, _TrainW2V_KerasRoyal_, that demonstrates how word embeddings are created from scratch (using keras) along with a small corresponding input data file, _royalData_.
* Python notebook, _TrainW2V_GenSimText8_, that demonstrates training a much larger word embedding model (using gensim) on an API accessible dataset.

Some additional links for exploring word embeddings
* Demo: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/index.html
* Tutorial: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/tutorial.html
* Experiments: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/experiments.html
* Published Paper: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/EAAI-2022-Word-Embedding.pdf
