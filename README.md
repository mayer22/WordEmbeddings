# Word Embedding Resources
I have provided several resources for learning about word embeddings, specifically Word2Vec.

* Lecture slides that introduce and explain word embeddings. They also compares Word2Vec to other NLP techniques and identifies its importance to NLP through visualizations.
* Python notebook, TrainW2V_Scratch, that demonstrates how word embeddings are created from scratch (using keras) along with a small corresponding input data file, royalData.
* Python notebook, TrainW2V_Scratch, that demonstrates training a much larger word embedding model (using gensim) along with a corresponding input data file.

Some additional links for exploring word embeddings
* Demo: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/index.html (currently not working)
* Tutorial: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/tutorial.html
* Experiments: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/experiments.html
