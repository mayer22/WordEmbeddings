{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef865e9a-9f02-477f-90b1-48139136d400",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8016669-8d4c-4539-816b-98547d59abad",
   "metadata": {},
   "source": [
    "This is a dataset available via an api download from gensim directly.\n",
    "\n",
    "There are other datasets available that you can try along with pretrained models.\n",
    "\n",
    "https://github.com/piskvorky/gensim-data?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abaebf-ead0-4b02-a26e-f4ba32ffd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "corpus = api.load('text8')  # download the corpus and return it opened as an iterable\n",
    "#text8 is the first 90 million characters from a Wikipedia dump/extract in March 2006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bdc2a-e82e-44d8-904e-1f5b2cc30099",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e218984-d239-4cc4-93e9-3b515a65f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT RUN ME IN LECTURE\n",
    "\n",
    "#gsmodel = Word2Vec(corpus)  # simple call\n",
    "gsmodel = gensim.models.Word2Vec(corpus, min_count=1, vector_size=100, window=5, sg=1) # sg=1 for skip-gram or 0 for CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47ace7-2430-4066-bbf6-5acf81503da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print an embedding\n",
    "print(gsmodel.wv['car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e798fd2-46be-4768-ad4a-3df18a96a915",
   "metadata": {},
   "source": [
    "# **STOP HERE AND GO BACK TO SLIDES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430a329-656c-4803-ab53-5ec3a150300c",
   "metadata": {},
   "source": [
    "# Reduce dimensions and plot embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72e346-1ed3-4c61-957e-fdf94b4b4a4f",
   "metadata": {},
   "source": [
    "### MDS Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a205e-a95f-4f13-88e7-2a6b73fad0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get frequent terms to plot\n",
    "terms = gsmodel.wv.index_to_key[100:200] #didn't get the most frequent to avoid stopwords\n",
    "\n",
    "termVectors = np.array([gsmodel.wv[word] for word in terms])\n",
    "#termVectors.shape #100 words, 100 dimensions \n",
    "\n",
    "# Compute the pairwise Euclidean distances using pdist\n",
    "distance_matrix = pdist(termVectors, metric='euclidean')\n",
    "distance_matrix_square = squareform(distance_matrix) # Convert the distance vector to a square distance matrix\n",
    "#print(\"Distance Matrix:\\n\", distance_matrix_square)\n",
    "\n",
    "# Run MDS using the distance matrix\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "embedding = mds.fit_transform(distance_matrix_square)\n",
    "\n",
    "# Plot the MDS result\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1])\n",
    "for i, (x, y) in enumerate(embedding):\n",
    "    plt.text(x, y, terms[i], fontsize=12, ha='right')\n",
    "plt.title(\"MDS 2D Representation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c86f5-2e41-431f-812b-b84454e7488e",
   "metadata": {},
   "source": [
    "### PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d33337-bd9a-48a4-b8d4-f6f14e196487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get frequent terms to plot\n",
    "terms = gsmodel.wv.index_to_key[200:300] #didn't get the most frequent to avoid stopwords\n",
    "\n",
    "termVectors = np.array([gsmodel.wv[word] for word in terms])\n",
    "#termVectors.shape #100 words, 100 dimensions \n",
    "\n",
    "pca = PCA() # init PCA object\n",
    "pca.fit(termVectors) # the fit function determines the new dimensions or axes to represent the data -- the result is sent back to the pca object\n",
    "\n",
    "#transform the data\n",
    "result = pca.transform(termVectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18c998-3730-4bb3-ac88-44480206e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(result[:,0], result[:,1])\n",
    "for i, word in enumerate(terms):\n",
    "  plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86fb05-e5ff-40f2-bea0-e96b782743d1",
   "metadata": {},
   "source": [
    "# Explore Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16af01e-e11c-497e-b492-f92bf7a51ed5",
   "metadata": {},
   "source": [
    "### Most/Least similar terms based on Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3233de-705d-4579-87b8-bb0680ba2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsmodel.wv.most_similar(positive=['car'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67450900-da63-4cc2-ba98-aa3c775e4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsmodel.wv.most_similar(negative=['italy'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c975325-76cd-40da-83c8-035e0ad81743",
   "metadata": {},
   "source": [
    "### Identify similarity based on Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a68fd2-e639-4da9-9803-4d2e16fe5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the words you want to compare\n",
    "baseW = 'car' #Choose a base word\n",
    "simW = 'truck' #Choose a word that might be similar to the base word\n",
    "diffW = 'bike' #Choose a word that might be different from the base word\n",
    "\n",
    "# print comparisons\n",
    "print(\"The cosine similarity between \", baseW, \" and \", simW, \" is \", gsmodel.wv.similarity(baseW, simW))\n",
    "\n",
    "print(\"The cosine similarity between \", baseW, \" and \", diffW, \" is \", gsmodel.wv.similarity(baseW, diffW))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4786e-132f-4f35-92cf-3f87e35337d4",
   "metadata": {},
   "source": [
    "### Vector arithmetic for analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a129c-4031-47a9-a53d-3e6e808d7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract man from king then add woman\n",
    "print(gsmodel.wv.most_similar(positive=['king','woman'], negative=['man'], topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd1045-2895-4993-bc9a-f80e58172165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract he from she\n",
    "gsmodel.wv.most_similar(positive=['she'], negative=['he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32795f-bd18-4b2b-8474-29b23b67d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract she from he\n",
    "gsmodel.wv.most_similar(positive=['he'], negative=['she'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a500653-f36f-4d68-80b6-1ec7d16a112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsmodel.wv.most_similar(positive=['she','her','hers','herself','he','him','his','himself'], topn=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
